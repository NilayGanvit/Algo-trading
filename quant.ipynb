{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from scripy.stats import boxcox\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from scipy.stats import jarque_bera\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "from talib import RSI, BBANDS, MACD, STOCH, ATR, OBV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from talib import WMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=pd.IndexSlice\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    df=pd.read_csv('data.csv',index_col=[0],parse_dates=['Date'])\n",
    "    df=df.sort_values(['Ticker','Date'])\n",
    "    df=df.dropna()\n",
    "    return df\n",
    "\n",
    "def get_ticker_data(df,ticker):\n",
    "    df=df.loc[idx[ticker,:],:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_features(df,feature):\n",
    "    df=df.sort_values(feature,ascending=False)\n",
    "    df[feature+'_rank']=np.arange(1,len(df)+1)\n",
    "    df=df.sort_values(['Date','Ticker'])\n",
    "    return df\n",
    "\n",
    "def get_feature_rank(df,feature):\n",
    "    df=df.loc[:,[feature+'_rank']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(df,feature):\n",
    "    df=df.loc[:,[feature]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(df,feature):\n",
    "    df=df.sort_values(feature,ascending=False)\n",
    "    df['rank']=np.arange(1,len(df)+1)\n",
    "    df=df.sort_values(['Date','Ticker'])\n",
    "    return df\n",
    "\n",
    "def get_rank(df):\n",
    "    df=df.loc[:,['rank']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df,feature):\n",
    "    df[feature+'_scaled']=StandardScaler().fit_transform(df[[feature]])\n",
    "    return df\n",
    "\n",
    "def get_scaled(df,feature):\n",
    "    df=df.loc[:,[feature+'_scaled']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(df,feature):\n",
    "    df[feature+'_log']=np.log(df[feature])\n",
    "    return df\n",
    "\n",
    "def get_log(df,feature):\n",
    "    df=df.loc[:,[feature+'_log']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal(df,feature):\n",
    "    df[feature+'_signal']=np.where(df[feature]>0,1,0)\n",
    "    return df\n",
    "\n",
    "def get_signal(df,feature):\n",
    "    df=df.loc[:,[feature+'_signal']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(df,feature):\n",
    "    df=df.loc[:,[feature]]\n",
    "    return df\n",
    "\n",
    "def get_features(df,features):\n",
    "    df=df.loc[:,features]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_transform(df,feature):\n",
    "    df[feature+'_power']=stats.boxcox(df[feature])[0]\n",
    "    return df\n",
    "\n",
    "def get_power(df,feature):\n",
    "    df=df.loc[:,[feature+'_power']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(df,exp,feature):\n",
    "    df[feature+'_power']=df[feature]**exp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts(df,feature):\n",
    "    df[feature+'_ts']=df[feature].shift(1)\n",
    "    return df\n",
    "\n",
    "def get_ts(df,feature):\n",
    "    df=df.loc[:,[feature+'_ts']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_diff(df,feature):\n",
    "    df[feature+'_ts_diff']=df[feature].diff(1)\n",
    "    return df\n",
    "\n",
    "def get_ts_diff(df,feature):\n",
    "    df=df.loc[:,[feature+'_ts_diff']]\n",
    "    return df\n",
    "\n",
    "def ts_pct(df,feature):\n",
    "    df[feature+'_ts_pct']=df[feature].pct_change(1)\n",
    "    return df\n",
    "\n",
    "def get_ts_pct(df,feature):\n",
    "    df=df.loc[:,[feature+'_ts_pct']]\n",
    "    return df\n",
    "\n",
    "def ts_log(df,feature):\n",
    "    df[feature+'_ts_log']=np.log(df[feature])\n",
    "    return df\n",
    "\n",
    "def get_ts_log(df,feature):\n",
    "    df=df.loc[:,[feature+'_ts_log']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_delta(df,feature):\n",
    "    df[feature+'_ts_delta']=df[feature]-df[feature+'_ts']\n",
    "    return df\n",
    "\n",
    "def get_ts_delta(df,feature):\n",
    "    df=df.loc[:,[feature+'_ts_delta']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv=['Open','High','Low','Close','Volume']\n",
    "\n",
    "def get_ohlcv(df):\n",
    "    df=df.loc[:,ohlcv]\n",
    "    return df\n",
    "\n",
    "data=get_data()\n",
    "\n",
    "data=data.loc[idx[:,'2010-01-01':'2020-12-31'],:]\n",
    "\n",
    "data=data.dropna()\n",
    "\n",
    "data=data.drop_duplicates()\n",
    "\n",
    "data=data.drop(['Open','High','Low','Close','Volume'],axis=1)\n",
    "\n",
    "data=data.drop(['Market Cap','Enterprise Value','Shares Outstanding','Shares Short (prior month )','Float','Shares Short','Shares Short (prior month)','Shares Short (Jan 14, 2021)','Shares Short (prior month Dec 14, 2020)'],axis=1)\n",
    "\n",
    "data=data.drop(['Forward Annual Dividend Rate','Forward Annual Dividend Yield','Trailing Annual Dividend Rate','Trailing Annual Dividend Yield','5 Year Average Dividend Yield','Payout Ratio','Dividend Date','Ex-Dividend Date'],axis=1)\n",
    "\n",
    "data=data.drop(['Fiscal Year Ends','Most Recent Quarter (mrq)','Profit Margin','Operating Margin (ttm)','Return on Assets (ttm)','Return on Equity (ttm)','Revenue (ttm)','Revenue Per Share (ttm)','Quarterly Revenue Growth (yoy)','Gross Profit (ttm)','EBITDA','Net Income Avi to Common (ttm)','Diluted EPS (ttm)','Quarterly Earnings Growth (yoy)','Total Cash (mrq)','Total Cash Per Share (mrq)','Total Debt (mrq)','Total Debt/Equity (mrq)','Current Ratio (mrq)','Book Value Per Share (mrq)','Operating Cash Flow (ttm)','Levered Free Cash Flow (ttm)'],axis=1)\n",
    "\n",
    "data=data.drop(['Forward P/E','PEG Ratio (5 yr expected)','Enterprise Value/Revenue','Enterprise Value/EBITDA','Beta (5Y Monthly)','52-Week Change','S&P500 52-Week Change','52 Week High 3','52 Week Low 3','50-Day Moving Average 3','200-Day Moving Average 3','Avg Vol (3 month) 3','Avg Vol (10 day) 3','Shares Outstanding 5','Float 5','% Held by Insiders 1','% Held by Institutions 1','% Shorted (previous month ) 4','% of Float Shorted (previous month ) 4','Short Ratio (Dec 14, 2020) 4','Short % of Shares Outstanding (Dec 14, 2020) 4','Short % of Float (Dec 14, 2020) 4','Shares Short (prior month Nov 12, 2020) 4','Forward Annual Dividend Rate 4','Forward Annual Dividend Yield 4','Trailing Annual Dividend Rate 3','Trailing Annual Dividend Yield 3','5 Year Average Dividend Yield 4','Payout Ratio 4','Dividend Date 3','Ex-Dividend Date 4','Last Split Factor (new per old) 2','Last Split Date 3'],axis=1)\n",
    "\n",
    "data=data.drop(['Fiscal Year Ends 3','Most Recent Quarter (mrq) 3','Profit Margin 3','Operating Margin (ttm) 3','Return on Assets (ttm) 3','Return on Equity (ttm) 3','Revenue (ttm) 3','Revenue Per Share (ttm) 3','Quarterly Revenue Growth (yoy) 3','Gross Profit (ttm) 3','EBITDA 3','Net Income Avi to Common (ttm) 3','Diluted EPS (ttm) 3','Quarterly Earnings Growth (yoy) 3','Total Cash (mrq) 3','Total Cash Per Share (mrq) 3','Total Debt (mrq) 3','Total Debt/Equity (mrq) 3','Current Ratio (mrq) 3','Book Value Per Share (mrq) 3','Operating Cash Flow (ttm) 3','Levered Free Cash Flow (ttm) 3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv20=data['Average Daily Volume (10 day)'].rolling(20).mean()\n",
    "\n",
    "data['Average Daily Volume (10 day)']=data['Average Daily Volume (10 day)'].fillna(adv20)\n",
    "\n",
    "data=data.dropna()\n",
    "\n",
    "data=data.drop(['Average Daily Volume (10 day)'],axis=1)\n",
    "\n",
    "data=data.assign(Adj_Close=data['Adj Close'])\n",
    "\n",
    "data=data.drop(['Adj Close'],axis=1)\n",
    "\n",
    "data=data.assign(adv20=data['Volume'].rolling(20).mean())\n",
    "\n",
    "data=data.join(data['adv20'].rolling(20).mean(),rsuffix='_20')\n",
    "\n",
    "data=data.drop(['adv20'],axis=1)\n",
    "\n",
    "data.info()\n",
    "\n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_hdf('data.h5','data')\n",
    "\n",
    "data=pd.read_hdf('data.h5','data')\n",
    "\n",
    "data=data.dropna()\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = data.open.unstack().rename_axis('date').reset_index()\n",
    "\n",
    "h = data.high.unstack().rename_axis('date').reset_index()\n",
    "\n",
    "l = data.low.unstack().rename_axis('date').reset_index()\n",
    "\n",
    "c = data.close.unstack().rename_axis('date').reset_index()\n",
    "\n",
    "v = data.volume.unstack().rename_axis('date').reset_index()\n",
    "\n",
    "o=o.rename(columns={'level_0':'ticker','open':'Open'})\n",
    "\n",
    "h=h.rename(columns={'level_0':'ticker','high':'High'})\n",
    "\n",
    "l=l.rename(columns={'level_0':'ticker','low':'Low'})\n",
    "\n",
    "c=c.rename(columns={'level_0':'ticker','close':'Close'})\n",
    "\n",
    "v=v.rename(columns={'level_0':'ticker','volume':'Volume'})  \n",
    "\n",
    "data=pd.merge(o,h,on=['ticker','date'])\n",
    "\n",
    "data=pd.merge(data,l,on=['ticker','date'])\n",
    "\n",
    "data=pd.merge(data,c,on=['ticker','date'])\n",
    "\n",
    "data=pd.merge(data,v,on=['ticker','date'])\n",
    "\n",
    "data=data.dropna()\n",
    "\n",
    "data=data.set_index(['ticker','date'])\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=data['Volume']\n",
    "\n",
    "v=v.unstack()\n",
    "\n",
    "v=v.fillna(method='ffill')\n",
    "\n",
    "v=v.stack()\n",
    "\n",
    "data['Volume']=v\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwap=data['Volume Weighted Average Price']\n",
    "\n",
    "vwap=vwap.unstack()\n",
    "\n",
    "vwap=vwap.fillna(method='ffill')\n",
    "\n",
    "vwap=vwap.stack()\n",
    "\n",
    "data['Volume Weighted Average Price']=vwap\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwap=o.add(h).add(l).add(c).div(4).mul(v).sum().div(v.sum())\n",
    "\n",
    "adv20=data['Volume'].rolling(20).mean() \n",
    "\n",
    "r=data['Close'].pct_change()\n",
    "\n",
    "r20=r.rolling(20).std()\n",
    "\n",
    "r20=r20.mul(np.sqrt(252))\n",
    "\n",
    "data=data.assign(adv20=adv20,r=r,r20=r20,vwap=vwap)\n",
    "\n",
    "data=data.dropna()\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=data.returns.unstack(\"ticker\")\n",
    "\n",
    "r=r.fillna(method='ffill')\n",
    "\n",
    "r=r.stack(\"ticker\")\n",
    "\n",
    "data['returns']=r\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPOTHESIS: If the stock price of a company has increased over the last 2 days, it may decrease in the future (time series delta of closing price today and closing price 2 days ago).\n",
    "\n",
    "# IMPLEMENTATION: If company A's stock price had increased twice as much as the stock price of another company B, the prices of both stocks may decrease in the future.  In this reversion example, stock A may not fall double stock B, though it may fall more than stock B (rank operator).\n",
    "\n",
    "# HINT: Can different neutralizations and decay settings improve this signal? Under what neutralization would a reversion idea work best?\n",
    "\n",
    "rank(-ts_delta(close,2))\n",
    "\n",
    "# different neutralizations and decay settings improve this signal\n",
    "\n",
    "rank(-ts_delta(close,2),neutralize=sector)\n",
    "\n",
    "rank(-ts_delta(close,2),decay=5)\n",
    "\n",
    "rank(-ts_delta(close,2),decay=5,neutralize=sector)\n",
    "\n",
    "# neutralization would a reversion idea work best\n",
    "\n",
    "rank(-ts_delta(close,2),neutralize=sector).quantiles(5)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
